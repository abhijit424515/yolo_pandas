{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading detection data\n",
    "X_train = torchvision.datasets.VOCDetection(root=\"content/voc\",\n",
    "                                                image_set=\"train\",\n",
    "                                                download=True,\n",
    "                                                year=\"2007\")\n",
    "X_val = torchvision.datasets.VOCDetection(root=\"content/voc\",\n",
    "                                                image_set=\"val\",\n",
    "                                                download=True,\n",
    "                                                year=\"2007\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_objs = []\n",
    "for ds in X_train:\n",
    "    obj_annots = ds[1][\"annotation\"][\"object\"]\n",
    "    for obj in obj_annots:\n",
    "        all_objs.append(obj[\"name\"])\n",
    "\n",
    "unique_class_labels = set(all_objs)\n",
    "print(\"Number of unique objects in dataset: \", len(unique_class_labels))\n",
    "print(\"Unique labels in dataset: \\n\", unique_class_labels)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
